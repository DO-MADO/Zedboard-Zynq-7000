# ============================================================
# ğŸ“‚ pipeline.py
# ëª©ì : ì‹¤ì‹œê°„ ì‹ í˜¸ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ (ìˆ˜ì • ë²„ì „)
# ì…ë ¥: Synthetic / CProc / IIO ì†ŒìŠ¤
# ì²˜ë¦¬: ì´ë™í‰ê·  â†’ LPF â†’ ë‹¤ìš´ìƒ˜í”Œë§ â†’ 4ìŒì˜ íŒŒìƒ ì‹ í˜¸ ë™ì‹œ ê³„ì‚°
# ì¶œë ¥: WebSocket JSON payload (ì‹¤ì‹œê°„ ì°¨íŠ¸/ë¶„ì„ìš©)
# ============================================================

# ----------------- [1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸] -----------------
import asyncio
import json
import struct
import subprocess
import threading
import time
import csv
from datetime import datetime
from dataclasses import dataclass, field
from pathlib import Path
from typing import Optional, List, Dict, Any

import numpy as np
from scipy.signal import butter, sosfilt, sosfilt_zi


# ----------------- [2. íŒŒë¼ë¯¸í„° ì •ì˜] -----------------
@dataclass
class PipelineParams:
    # filtering / averaging / rate
    lpf_cutoff_hz: float = 5_000.0
    lpf_order: int = 4
    movavg_ch: int = 8
    movavg_r: int = 4
    target_rate_hz: float = 100.0

<<<<<<< Updated upstream
    # derived stage and quad selection (ì°¸ê³ ìš©ìœ¼ë¡œ ìœ ì§€, ìƒˆ ë¡œì§ì—ì„œëŠ” ë¯¸ì‚¬ìš©)
    derived: str = "yt"   # "R" | "Ravg" | "y1" | "y2" | "y3" | "yt"
    out_ch: int = 0       # treated as quad index: 0 -> ch0..3, 1 -> ch4..7
=======
    # -----------------------------
    # [í•„í„°ë§ / í‰ê·  / ì¶œë ¥ ì†ë„]
    # -----------------------------
    lpf_cutoff_hz: float = 2_500.0         # ì €ì—­í†µê³¼í•„í„°(LPF) ì°¨ë‹¨ ì£¼íŒŒìˆ˜ (Hz)
    lpf_order: int = 4                     # LPF ì°¨ìˆ˜
    movavg_ch: int = 1000  # â€¼ï¸ ê¸°ë³¸ ìƒ˜í”Œ ìˆ˜ë„ 0.001ì´ˆì— ë§ì¶° ë³€ê²½ (1000ê°œ)
    movavg_r: int = 5      # â€¼ï¸ ê¸°ë³¸ ìƒ˜í”Œ ìˆ˜ë„ 0.5ì´ˆì— ë§ì¶° ë³€ê²½ (5ê°œ @ 10Hz)
    
    # â€¼ï¸ ì‚¬ìš©ìê°€ ì²´ê°í•˜ê¸° ì¢‹ì€, ë” ì‹¤ìš©ì ì¸ ê¸°ë³¸ê°’ìœ¼ë¡œ ë³€ê²½
    movavg_ch_sec: float = 0.001  # (ê¸°ì¡´: 0.000008)
    movavg_r_sec: float = 0.5    # (ê¸°ì¡´: 0.4)
    
    
    target_rate_hz: float = 10.0           # ì‹œê°„í‰ê· (Time Average) ì ìš© í›„ ëª©í‘œ ì¶œë ¥ ì†ë„
    
    # -----------------------------
    # [ì°¸ê³ ìš© ì˜µì…˜ - í˜„ì¬ ë¡œì§ì—ì„œëŠ” ë¯¸ì‚¬ìš©]
    # -----------------------------
    derived: str = "yt"    # ì„ íƒ ê°€ëŠ¥í•œ íŒŒìƒ ì‹ í˜¸ ("R","Ravg","y1","y2","y3","yt")
    out_ch: int = 0        # ì¶œë ¥ ê·¸ë£¹ (0=ch0~3, 1=ch4~7)
>>>>>>> Stashed changes

    # ---- 10-stage coefficients ----
    # â‘£ R = Î±Î²Î³ * log_k(I_sensor / I_standard) + b
    alpha: float = 1.0
    beta: float = 1.0
    gamma: float = 1.0
    k: float = 10.0        # ê¸°ë³¸: ìƒìš©ë¡œê·¸. (ì£¼ì˜: k<=0 ë˜ëŠ” k==1 ê¸ˆì§€)
    b: float = 0.0

    # â‘¥ y1 = polyval(y1_num, Ravg) / polyval(y1_den, Ravg)
    y1_num: List[float] = field(default_factory=lambda: [1.0, 0.0])
    y1_den: List[float] = field(default_factory=lambda: [0.0, 0.0, 0.0, 0.01, 0.05, 1.0])
    
    # â‘¦ y2 = polyval(y2_coeffs, y1)
    y2_coeffs: List[float] = field(default_factory=lambda: [0.0, 0.0, 0.0, -0.01, 0.90, 0.0])

    # â‘§ y3 = polyval(y3_coeffs, y2)
    y3_coeffs: List[float] = field(default_factory=lambda: [0.0, 0.0, 0.0, 0.0, 1.0, 0.0])


    # â‘¨ yt = E * y3 + F
    E: float = 1.0
    F: float = 0.0

    # â‘£ ì•ˆì „ì¥ì¹˜: ì ˆëŒ“ê°’ ì •ë¥˜
    r_abs: bool = True

    # --- ë©€í‹° ì¶œë ¥ ì»¨íŠ¸ë¡¤ (ì°¸ê³ ìš©ìœ¼ë¡œ ìœ ì§€, ìƒˆ ë¡œì§ì—ì„œëŠ” ë¯¸ì‚¬ìš©) ---
    derived_multi: str = "yt_4"

    def model_dump(self) -> Dict[str, Any]:
        return {
<<<<<<< Updated upstream
            "lpf_cutoff_hz": self.lpf_cutoff_hz,
            "lpf_order": self.lpf_order,
            "movavg_ch": self.movavg_ch,
            "movavg_r": self.movavg_r,
            "target_rate_hz": self.target_rate_hz,
            "derived": self.derived,
            "out_ch": self.out_ch,
            "alpha": self.alpha, "beta": self.beta,
            "gamma": self.gamma, "k": self.k, "b": self.b,
            "y1_num": self.y1_num, "y1_den": self.y1_den,
            "y2_coeffs": self.y2_coeffs,
            "y3_coeffs": self.y3_coeffs,
            "E": self.E, "F": self.F,
            "r_abs": self.r_abs,
            "derived_multi": self.derived_multi,
=======
            "sampling_frequency": self.sampling_frequency,   # ìƒ˜í”Œë§ ì£¼íŒŒìˆ˜ (Hz)
            "block_samples": self.block_samples,             # ë¸”ë¡ í¬ê¸° (ìƒ˜í”Œ ìˆ˜)
            "lpf_cutoff_hz": self.lpf_cutoff_hz,             # LPF ì°¨ë‹¨ ì£¼íŒŒìˆ˜
            "lpf_order": self.lpf_order,                     # LPF ì°¨ìˆ˜
            "movavg_ch": self.movavg_ch,                     # ì±„ë„ ì´ë™í‰ê·  í¬ê¸°
            "movavg_r": self.movavg_r,                       # R ì´ë™í‰ê·  í¬ê¸°
            "movavg_ch_sec": self.movavg_ch_sec,             # ì±„ë„ ì´ë™í‰ê·  (ì´ˆ ë‹¨ìœ„)
            "movavg_r_sec": self.movavg_r_sec,               # R ì´ë™í‰ê·  (ì´ˆ ë‹¨ìœ„)
            "target_rate_hz": self.target_rate_hz,           # ì‹œê°„í‰ê·  í›„ ëª©í‘œ ì¶œë ¥ ì†ë„ (S/s)
            "derived": self.derived,                         # (ì°¸ê³ ìš©) íŒŒìƒ ì‹ í˜¸ ì„ íƒ
            "out_ch": self.out_ch,                           # ì¶œë ¥ ê·¸ë£¹ ì„ íƒ
            "alpha": self.alpha, "beta": self.beta,          # R ê³„ì‚° ê³„ìˆ˜ Î±, Î²
            "gamma": self.gamma, "k": self.k, "b": self.b,   # R ê³„ì‚° ê³„ìˆ˜ Î³, k, b
            "y1_num": self.y1_num, "y1_den": self.y1_den,    # y1 ë³´ì • ë‹¤í•­ì‹ (ë¶„ì/ë¶„ëª¨)
            "y2_coeffs": self.y2_coeffs,                     # y2 ë³´ì • ë‹¤í•­ì‹ ê³„ìˆ˜
            "y3_coeffs": self.y3_coeffs,                     # y3 ë³´ì • ë‹¤í•­ì‹ ê³„ìˆ˜
            "E": self.E, "F": self.F,                        # ìµœì¢… yt ë³´ì • ê³„ìˆ˜
            "r_abs": self.r_abs,                             # R ì ˆëŒ“ê°’ ì²˜ë¦¬ ì—¬ë¶€
            "derived_multi": self.derived_multi,             # ë©€í‹° ì¶œë ¥ ëª¨ë“œ (ì°¸ê³ ìš©)
>>>>>>> Stashed changes
        }

# ----------------- [3. í—¬í¼ í•¨ìˆ˜] -----------------

# ##### [ì¶”ê°€] ê³ ìœ í•œ ë¡œê·¸ íŒŒì¼ ê²½ë¡œë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ #####
def get_unique_log_path(directory: Path, base_name: str, extension: str) -> Path:
    """
    ì§€ì •ëœ ë””ë ‰í† ë¦¬ ë‚´ì—ì„œ ê²¹ì¹˜ì§€ ì•ŠëŠ” íŒŒì¼ ê²½ë¡œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    (ì˜ˆ: stream_log.csv, stream_log_1.csv, stream_log_2.csv ...)
    """
    counter = 1
    file_path = directory / f"{base_name}{extension}"
    
    # íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•˜ë©´, ì´ë¦„ ë’¤ì— ìˆ«ìë¥¼ ë¶™ì—¬ ìƒˆ ê²½ë¡œë¥¼ íƒìƒ‰
    while file_path.exists():
        file_path = directory / f"{base_name}_{counter}{extension}"
        counter += 1
    
    return file_path
# ##### [ì¶”ê°€ ë] #####

def moving_average(x: np.ndarray, N: int) -> np.ndarray:
    if N is None or N <= 1:
        return x
    c = np.ones(N, dtype=float) / float(N)
    return np.convolve(x, c, mode="same")

def sanitize_array(x: np.ndarray) -> np.ndarray:
    return np.nan_to_num(x, nan=0.0, posinf=1e12, neginf=-1e12)

def design_lpf(fs_hz: float, cutoff_hz: float, order: int):
    nyq = 0.5 * fs_hz
    wn = max(1e-6, min(0.999999, cutoff_hz / nyq))
    return butter(order, wn, btype="low", output="sos")

# ##### LPF í•¨ìˆ˜ ìˆ˜ì •: í•„í„° ìƒíƒœ(zi, zf)ë¥¼ ì¸ìë¡œ ë°›ë„ë¡ ë³€ê²½ --> ê·¸ë˜í”„ íŒŒí˜•ì— ìˆœê°„ 0v ì°íˆëŠ”ê±° í”½ìŠ¤#####
def apply_lpf(x: np.ndarray, sos, zi):
    y, zf = sosfilt(sos, x, zi=zi)
    return y, zf

# íŒŒìƒ ì‹ í˜¸ ê³„ì‚°ì„ ìœ„í•œ í•µì‹¬ í—¬í¼ í•¨ìˆ˜ (top: ë¶„ì, bot: ë¶„ëª¨)
def _compute_yt_from_top_bot(params: PipelineParams, top: np.ndarray, bot: np.ndarray) -> np.ndarray:
    eps = 1e-12
    if params.r_abs:
        top, bot = np.abs(top), np.abs(bot)
    top, bot = np.maximum(top, eps), np.maximum(bot, eps)

    # ë°‘ì´ kì¸ ë¡œê·¸ë¥¼ ì‚¬ìš©í•˜ëŠ” R ê³„ì‚°
    ratio = np.maximum(top / bot, eps)
    # kê°€ 1 ì´í•˜ì¼ ê²½ìš° ìƒìš©ë¡œê·¸(10)ë¥¼ ì‚¬ìš©í•˜ë„ë¡ ì•ˆì „ì¥ì¹˜ ì¶”ê°€
    log_base = params.k if params.k > 1 else 10.0
    log_ratio = np.log(ratio) / np.log(log_base)

    scale = params.alpha * params.beta * params.gamma
    R = scale * log_ratio + params.b

    Ravg = moving_average(R, max(1, int(params.movavg_r)))

    # ì•ˆì •ì„±ì„ ìœ„í•´ clip ì¶”ê°€
    safe_ravg = np.clip(Ravg, -1e9, 1e9)
    n = np.polyval(np.array(params.y1_num, dtype=float), safe_ravg)
    d = np.polyval(np.array(params.y1_den, dtype=float), safe_ravg)
    y1 = n / np.where(np.abs(d) < eps, eps, d)

    safe_y1 = np.clip(y1, -1e9, 1e9)
    y2 = np.polyval(np.array(params.y2_coeffs, dtype=float), safe_y1)

    safe_y2 = np.clip(y2, -1e9, 1e9)
    y3 = np.polyval(np.array(params.y3_coeffs, dtype=float), safe_y2)

    yt = params.E * y3 + params.F

    return sanitize_array(yt).astype(np.float32, copy=False)


# ----------------- [4. Source í´ë˜ìŠ¤ ê³„ì¸µ] -----------------
class SourceBase:
    def read_block(self, n_samples: int) -> np.ndarray:
        raise NotImplementedError

class SyntheticSource(SourceBase):
    def __init__(self, fs_hz: float, f_sig: float = 3e3, snr_db: float = 20.0, n_ch: int = 8):
        self.fs = fs_hz
        self.f = f_sig
        self.n = 0
        self.snr_db = snr_db
        self.n_ch = n_ch

    def read_block(self, n_samples: int) -> np.ndarray:
        t = (np.arange(n_samples) + self.n) / self.fs
        self.n += n_samples
        data = []
        for k in range(self.n_ch):
            sig = np.sin(2*np.pi*(self.f + k*10)*t)
            p_sig = np.mean(sig**2)
            p_n = p_sig / (10.0 ** (self.snr_db/10.0))
            noise = np.random.normal(scale=np.sqrt(p_n), size=n_samples)
            data.append(sig + noise)
        return np.stack(data, axis=1).astype(np.float32, copy=True)

class CProcSource(SourceBase):
    def __init__(self, exe_path: str, ip: str, block_samples: int):
        self.block = int(block_samples)
        self.proc = subprocess.Popen(
            [exe_path, ip, str(self.block)],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            bufsize=0
        )
        self._stdout = self.proc.stdout
        self._hdr_struct = struct.Struct("<II")

    def _read_exact(self, n: int) -> bytes:
        buf = bytearray()
        while len(buf) < n:
            chunk = self._stdout.read(n - len(buf))
            if not chunk:
                raise EOFError("CProc stdout ended")
            buf.extend(chunk)
        return bytes(buf)

    def read_block(self, n_samples: int) -> np.ndarray:
        hdr = self._read_exact(self._hdr_struct.size)
        n_samp, n_ch = self._hdr_struct.unpack(hdr)
        total = n_samp * n_ch * 4
        raw = self._read_exact(total)
        arr = np.frombuffer(raw, dtype=np.float32).copy()
        return arr.reshape((n_samp, n_ch))

class IIOSource(SourceBase):
    def __init__(self, uri: str, fs_hz: float, n_ch_guess: int = 8):
        import iio
        self.ctx = iio.Context(uri)
        dev = None
        for d in self.ctx.devices:
            ins = [ch for ch in d.channels if not ch.output and ("voltage" in ch.id)]
            if ins:
                dev = d
                break
        if dev is None:
            raise RuntimeError("No input-capable IIO device found")
        self.dev = dev
        self.channels = [ch for ch in self.dev.channels if not ch.output and ("voltage" in ch.id)]
        for ch in self.channels:
            try:
                ch.enabled = True
            except Exception:
                pass
        self.fs = fs_hz

    def read_block(self, n_samples: int) -> np.ndarray:
        import iio
        buf = iio.Buffer(self.dev, n_samples, cyclic=False)
        buf.refill()
        cols = []
        for ch in self.channels:
            raw = ch.read(buf)
            arr = np.frombuffer(raw, dtype=np.int32).astype(np.float32, copy=True)
            cols.append(arr[:n_samples])
        return np.stack(cols, axis=1)


# ----------------- [5. Pipeline í´ë˜ìŠ¤] -----------------
class Pipeline:
    def __init__(self, mode: str, uri: str, fs_hz: float, block_samples: int, exe_path: str, params: PipelineParams):
        self.params = params
        self.fs = float(fs_hz)
        self.block = int(block_samples)
        self.mode = mode
        self.uri = uri
        self.exe = exe_path

<<<<<<< Updated upstream
        if mode == "synthetic":
=======
        # -------------------------
        # [ì†ŒìŠ¤ ë° ìŠ¤ë ˆë“œ ì´ˆê¸°í™”]
        # - Synthetic / IIO / CProc ì¤‘ ì„ íƒ
        # -------------------------
        self._init_source_and_thread()

        # -------------------------
        # [WebSocket ì†Œë¹„ì ê´€ë¦¬]
        # - ì—¬ëŸ¬ í´ë¼ì´ì–¸íŠ¸ê°€ ë™ì‹œì— êµ¬ë…í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ
        #   asyncio.Queue ëª©ë¡ì„ consumer í’€ë¡œ ê´€ë¦¬
        # -------------------------
        self._consumers: List[asyncio.Queue[str]] = []
        self._consumers_lock = threading.Lock()

        # -------------------------
        # [ë¡œê·¸ ë””ë ‰í† ë¦¬/íŒŒì¼ ì¤€ë¹„]
        # - ë‚ ì§œë³„ í´ë” ìƒì„± (YYYY-MM-DD)
        # - stream_log.csv : ì›ì‹œ + yt ì‹ í˜¸ ê¸°ë¡
        # - perf_log.csv   : ì„±ëŠ¥ ë©”íƒ€ ì •ë³´ ê¸°ë¡
        # -------------------------
        log_dir = Path(__file__).parent / "logs"
        today_dir = log_dir / time.strftime('%Y-%m-%d')
        today_dir.mkdir(parents=True, exist_ok=True)

        # íŒŒì¼ ì´ë¦„ ì¶©ëŒ ë°©ì§€ (ìë™ suffix ë¶™ì„)
        self._stream_log_path = get_unique_log_path(today_dir, "stream_log", ".csv")
        self._perf_log_path = get_unique_log_path(today_dir, "perf_log", ".csv")
        self._last_perf_log_time = time.time() 
        self._last_stream_log_time = time.time()

         # -------------------------
        # [stream_log.csv í—¤ë” ì‘ì„±]
        # -------------------------
        # â€¼ï¸ í—¤ë”ë¥¼ ìš”ì²­í•˜ì‹  ë‚´ìš©(ch0-7, Ravg0-3, yt0-3)ìœ¼ë¡œ ë³€ê²½í•©ë‹ˆë‹¤.
        stream_headers = [
            "ì‹œê°„", 
            "ch0", "ch1", "ch2", "ch3", "ch4", "ch5", "ch6", "ch7",
            "Ravg0", "Ravg1", "Ravg2", "Ravg3",
            "yt0", "yt1", "yt2", "yt3"
        ]
        with open(self._stream_log_path, 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerow(stream_headers)

        # -------------------------
        # [perf_log.csv í—¤ë” ì‘ì„±]
        # - ì‹œê°„ + ìƒ˜í”Œë§ ì†ë„ + ë¸”ë¡ í¬ê¸° + ë¸”ë¡ ì‹œê°„ + ì²˜ë¦¬ìœ¨
        # -------------------------
        perf_headers = ["ì‹œê°„", "ìƒ˜í”Œë§ ì†ë„(kS/s)", "ë¸”ë¡ í¬ê¸°(samples)", "ë¸”ë¡ ì‹œê°„(ms)", "ë¸”ë¡ ì²˜ë¦¬ëŸ‰(blocks/s)","ì‹¤ì œ ì²˜ë¦¬ëŸ‰(kS/s/ch)"]
        with open(self._perf_log_path, 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerow(perf_headers)

    # ============================================================
    #  [ì†ŒìŠ¤ ë° ìŠ¤ë ˆë“œ ì´ˆê¸°í™” ë©”ì„œë“œ]
    # ------------------------------------------------------------
    # - modeì— ë”°ë¼ ë°ì´í„° ì†ŒìŠ¤ ê°ì²´ ìƒì„±
    #   * cproc      : ì™¸ë¶€ C ì‹¤í–‰ íŒŒì¼ (iio_reader.exe)
    #   * synthetic  : ê°€ìƒ ì‚¬ì¸íŒŒ + ë…¸ì´ì¦ˆ ì‹ í˜¸
    #   * iio        : ì§ì ‘ IIO ì¥ì¹˜ ì ‘ê·¼
    # - í•„í„°/ì´ë™í‰ê· ì˜ ìƒíƒœ(zi, í)ë¥¼ ì´ˆê¸°í™”
    # - ë¡¤ë§ ìœˆë„ìš° ë²„í¼ë¥¼ ì¤€ë¹„ (ìµœê·¼ 5ì´ˆ êµ¬ê°„)
    # ============================================================
    def _init_source_and_thread(self):
        """ì†ŒìŠ¤ ê°ì²´ì™€ ì²˜ë¦¬ ìŠ¤ë ˆë“œë¥¼ ìƒì„±í•˜ê³  ê°ì¢… ìƒíƒœ ë³€ìˆ˜ë¥¼ ì´ˆê¸°í™”"""

        # -------------------------
        # [ë¸”ë¡ í¬ê¸° ì„¤ì •]
        # - PipelineParamsì—ì„œ block_samples ìš°ì„  ì‚¬ìš©
        # - ì—†ëŠ” ê²½ìš° self.block ê°’ ìœ ì§€
        # -------------------------
        block_samples = getattr(self.params, "block_samples", self.block)
        self.block = int(block_samples)

        # -------------------------
        # [ì†ŒìŠ¤ ê°ì²´ ì„ íƒ]
        # -------------------------
        if self.mode == "cproc":
            # ì™¸ë¶€ C ë¦¬ë” ì‹¤í–‰
            # exe_path, IP, ë¸”ë¡ í¬ê¸°, ìƒ˜í”Œë§ ì£¼íŒŒìˆ˜ ì „ë‹¬
            self.src = CProcSource(
                exe_path=self.exe,
                ip=self.uri,
                block_samples=self.block,
                fs_hz=self.fs
            )
        elif self.mode == "synthetic":
            # ê°€ìƒ ì‚¬ì¸íŒŒ + ë…¸ì´ì¦ˆ 8ì±„ë„ ìƒì„±ê¸°
>>>>>>> Stashed changes
            self.src = SyntheticSource(fs_hz=self.fs, n_ch=8)
        elif mode == "cproc":
            self.src = CProcSource(exe_path=self.exe, ip=self.uri.split(":")[-1] if ":" in self.uri else self.uri, block_samples=self.block)
        else:
            self.src = IIOSource(uri=self.uri, fs_hz=self.fs)

        self._stop = threading.Event()
        self._thread = threading.Thread(target=self._run, daemon=True)
        self._sos = design_lpf(self.fs, self.params.lpf_cutoff_hz, self.params.lpf_order)
        
        # ##### [ì½”ë“œ ì¶”ê°€] í•„í„° ìƒíƒœë¥¼ ì €ì¥í•  ë³€ìˆ˜ ì¶”ê°€ #####
        zi_one_ch = sosfilt_zi(self._sos)  #(Shape: [2, 2])
        n_ch_initial = 8
        self._lpf_state = np.stack([zi_one_ch] * n_ch_initial, axis=-1) #ì´ ìƒíƒœë¥¼ 8ê°œ ì±„ë„ë§Œí¼ ë³µì‚¬í•˜ì—¬ 3ì°¨ì› ë°°ì—´ë¡œ ë§Œë“­ë‹ˆë‹¤. (Shape: [2, 2, 8])
        self._n_ch_last = n_ch_initial
        
        # ##### [ì½”ë“œ ì¶”ê°€ ë] #####

<<<<<<< Updated upstream
        self._roll_sec = 5.0
        self._roll_len = int(max(1, self.params.target_rate_hz * self._roll_sec))
        self._roll_x = np.arange(self._roll_len, dtype=np.int32)
        self._roll_y = None
=======
        # ê° ì±„ë„ì— sosfilt ì´ˆê¸° ìƒíƒœ ë³µì œ
        zi_one_ch = sosfilt_zi(self._sos)
        self._lpf_state = np.stack([zi_one_ch] * n_ch_initial, axis=-1)

        # -------------------------
        # [ì´ë™í‰ê·  ì´ˆê¸°í™”]
        # - N>1ì´ë©´ ì§ì „ N-1 ìƒ˜í”Œ ë³´ê´€ìš© ë²„í¼ ì¤€ë¹„
        # -------------------------
        movavg_N = self.params.movavg_ch
        if movavg_N > 1:
            self._movavg_state = np.zeros((movavg_N - 1, n_ch_initial), dtype=np.float32)
        else:
            self._movavg_state = None


>>>>>>> Stashed changes

        self._consumers: List[asyncio.Queue[str]] = []
        self._consumers_lock = threading.Lock()

        # ##### [ìˆ˜ì •] ê³ ìœ í•œ ë¡œê·¸ íŒŒì¼ ê²½ë¡œ ìƒì„± ë° í—¤ë”(Header) ê¸°ë¡ #####
        log_dir = Path(__file__).parent / "logs"
        today_dir = log_dir / time.strftime('%Y-%m-%d')
        today_dir.mkdir(parents=True, exist_ok=True)

        # ê³ ìœ í•œ íŒŒì¼ ê²½ë¡œë¥¼ ë°›ì•„ì˜´
        self._stream_log_path = get_unique_log_path(today_dir, "stream_log", ".csv")
        self._perf_log_path = get_unique_log_path(today_dir, "perf_log", ".csv")
        self._last_perf_log_time = time.time() 
        self._last_stream_log_time = time.time()

        # --- stream_log.csv í—¤ë” ---
        # (ìƒˆ íŒŒì¼ì´ë¯€ë¡œ í•­ìƒ í—¤ë”ë¥¼ ìƒˆë¡œ ì”ë‹ˆë‹¤)
        stream_headers = [
            "ì‹œê°„", "ch0", "ch1", "ch2", "ch3", "ch4", "ch5", "ch6", "ch7",
            "yt0", "yt1", "yt2", "yt3",
            "LRFì„¤ì •", "Rí‰ê· ", "ì¶œë ¥ìƒ˜í”Œì†ë„"
        ]
        with open(self._stream_log_path, 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerow(stream_headers)

        # --- perf_log.csv í—¤ë” ---
        # (ìƒˆ íŒŒì¼ì´ë¯€ë¡œ í•­ìƒ í—¤ë”ë¥¼ ìƒˆë¡œ ì”ë‹ˆë‹¤)
        perf_headers = ["ì‹œê°„", "ë°ì´í„°ìˆ˜ì§‘(ms)", "ì‹ í˜¸ì²˜ë¦¬(ms)", "í™”ë©´ê°±ì‹ (Hz)", "ë£¨í”„ì²˜ë¦¬ëŸ‰(kS/s)"]
        with open(self._perf_log_path, 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerow(perf_headers)
        # ##### [ìˆ˜ì • ë] #####
        
        
    # ---------- coeffs I/O ----------
    @staticmethod
    def load_coeffs(path: Path):
        return json.loads(path.read_text(encoding="utf-8"))

    def save_coeffs(self, path: Path):
        data = self.params.model_dump()
        path.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding="utf-8")

    # ---------- consumers ----------
    def register_consumer(self) -> asyncio.Queue:
        q: asyncio.Queue[str] = asyncio.Queue(maxsize=2)
        with self._consumers_lock:
            self._consumers.append(q)
        return q

    def _broadcast(self, payload: dict):
        text = json.dumps(payload, separators=(",", ":"))
        with self._consumers_lock:
            for q in list(self._consumers):
                try:
                    if q.full():
                        _ = q.get_nowait()
                    q.put_nowait(text)
                except Exception:
                    pass

    # ---------- lifecycle ----------
    def start(self):
        self._thread.start()

    def stop(self):
        self._stop.set()
        try:
            if hasattr(self.src, "proc"):
                self.src.proc.terminate()
        except Exception:
            pass

    # ---------- params update/reset ----------
    def update_params(self, **kwargs):
        changed = {}
        for k, v in kwargs.items():
            if hasattr(self.params, k) and (v is not None) and getattr(self.params, k) != v:
                setattr(self.params, k, v)
                changed[k] = v
        if any(k in changed for k in ("lpf_cutoff_hz", "lpf_order")):
            self._sos = design_lpf(self.fs, self.params.lpf_cutoff_hz, self.params.lpf_order)
<<<<<<< Updated upstream
        if any(k in changed for k in ("target_rate_hz",)):
            self._roll_len = int(max(1, self.params.target_rate_hz * self._roll_sec))
            self._roll_x = np.arange(self._roll_len, dtype=np.int32)
            if self._roll_y is not None:
                n_ch = self._roll_y.shape[1]
                self._roll_y = np.zeros((self._roll_len, n_ch), dtype=np.float32)
=======

        # 2) ì´ë™í‰ê·  ìƒíƒœ ë¦¬ì…‹
        if "movavg_ch" in changed:
            movavg_N = self.params.movavg_ch
            n_ch = self._n_ch_last
            if movavg_N > 1:
                self._movavg_state = np.zeros((movavg_N - 1, n_ch), dtype=np.float32)
            else:
                self._movavg_state = None
   

>>>>>>> Stashed changes
        return changed

    def reset_params_to_defaults(self):
        self.params = PipelineParams()
<<<<<<< Updated upstream
        self._sos = design_lpf(self.fs, self.params.lpf_cutoff_hz, self.params.lpf_order)
        self._roll_len = int(max(1, self.params.target_rate_hz * self._roll_sec))
        self._roll_x = np.arange(self._roll_len, dtype=np.int32)
        if self._roll_y is not None:
            n_ch = self._roll_y.shape[1]
            self._roll_y = np.zeros((self._roll_len, n_ch), dtype=np.float32)

    # ---------- NEW: íŒŒìƒ ì‹ í˜¸ ê³„ì‚° ë¡œì§ ----------
=======
        # LPFë§Œ ì´ˆê¸°í™”í•˜ê³  ë¶ˆí•„ìš”í•´ì§„ ë¡¤ë§ ìœˆë„ìš° ê´€ë ¨ ì½”ë“œëŠ” ì‚­ì œ
        self._sos = design_lpf(self.fs, self.params.lpf_cutoff_hz, self.params.lpf_order)



    

    # ============================================================
    #  [íŒŒìƒ ì‹ í˜¸ ê³„ì‚° ë¡œì§]
    # ------------------------------------------------------------
    # ì…ë ¥: 8ì±„ë„ ë¸”ë¡ (y_block)
    #   - ì„¼ì„œ/í‘œì¤€ PD ì‹ í˜¸ë¥¼ 2ì±„ë„ì”© ë¬¶ì–´ ì´ 4ìŒìœ¼ë¡œ ë‚˜ëˆ”
    #       ìŒ ì •ì˜:
    #         (ch0:ì„¼ì„œ / ch1:í‘œì¤€) â†’ yt0
    #         (ch2:ì„¼ì„œ / ch3:í‘œì¤€) â†’ yt1
    #         (ch4:ì„¼ì„œ / ch5:í‘œì¤€) â†’ yt2
    #         (ch6:ì„¼ì„œ / ch7:í‘œì¤€) â†’ yt3
    #
    # ì²˜ë¦¬:
    #   - ê° ìŒì— ëŒ€í•´ _compute_yt_from_top_bot() í˜¸ì¶œ
    #     â†’ R ê³„ì‚° â†’ ì´ë™í‰ê·  â†’ y1 â†’ y2 â†’ y3 â†’ yt(E*y3+F)
    #   - ì•ˆì •ì„± ë³´ì¥: eps ì²˜ë¦¬, clip ì²˜ë¦¬, np.nan_to_num
    #
    # ì¶œë ¥(JSON ì§ë ¬í™” ê°€ëŠ¥í•œ dict):
    #   {
    #     "kind": "yt_4_pairs",
    #     "names": ["yt0","yt1","yt2","yt3"],
    #     "series": [list, list, list, list]   # ê° yt ì±„ë„ ì‹œí€€ìŠ¤
    #   }
    #
    # âœ… íŠ¹ì§•
    #   - 8ì±„ë„ ì…ë ¥ â†’ 4ì±„ë„ íŒŒìƒ ì¶œë ¥ìœ¼ë¡œ ì¶•ì†Œ
    #   - ì‹œê°í™”(Figure2 ë“±) ë° í›„ì²˜ë¦¬ì— ë°”ë¡œ í™œìš© ê°€ëŠ¥
    #   - ì…ë ¥ í¬ê¸°/ì±„ë„ ë¶€ì¡± ì‹œ ì•ˆì „í•˜ê²Œ ë¹ˆ ê²°ê³¼ ë°˜í™˜
    # ============================================================
>>>>>>> Stashed changes
    def _compute_derived_signals(self, y_block: np.ndarray) -> Dict[str, Any]:
        """
        8ì±„ë„ ì…ë ¥ì„ 2ê°œì”© ì§ì§€ì–´ 4ê°œì˜ ë…ë¦½ì ì¸ yt ì‹ í˜¸ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
        ìŒ: (ch1/ch0), (ch3/ch2), (ch5/ch4), (ch7/ch6)
        """
        # ì…ë ¥ ë°ì´í„°ê°€ ë¹„ì–´ìˆê±°ë‚˜ ì±„ë„ì´ ë¶€ì¡±í•˜ë©´ ë¹ˆ ê²°ê³¼ë¥¼ ë°˜í™˜
        if y_block.size == 0 or y_block.shape[1] < 8:
            return {
                "kind": "yt_4_pairs",
                "names": ["yt0", "yt1", "yt2", "yt3"],
                "series": [[], [], [], []]
            }

<<<<<<< Updated upstream
        # ì±„ë„ ì¸ë±ìŠ¤ ì •ì˜: ë¶„ì(ì„¼ì„œ), ë¶„ëª¨(í‘œì¤€)
        sensor_indices = [1, 3, 5, 7]   # I_1
        standard_indices = [0, 2, 4, 6] # I_2

        output_series = []
        for i in range(4):
            # ië²ˆì§¸ ìŒì— ëŒ€í•œ ì‹ í˜¸ ì¶”ì¶œ
            sensor_signal = y_block[:, sensor_indices[i]]
            standard_signal = y_block[:, standard_indices[i]]

            # ië²ˆì§¸ yt ê³„ì‚°
            yt_i = _compute_yt_from_top_bot(self.params, top=sensor_signal, bot=standard_signal)
            output_series.append(yt_i.tolist())
            
=======
        # ì„¼ì„œ/í‘œì¤€ ì±„ë„ ì¸ë±ìŠ¤ ì •ì˜
        sensor_indices = [0, 2, 4, 6]    # ë¶„ì(top): ì„¼ì„œ
        standard_indices = [1, 3, 5, 7]  # ë¶„ëª¨(bot): í‘œì¤€
        
        yt_series = []
        ravg_series = []
        output_series = []
        for i in range(4):
            sensor_signal = y_block[:, sensor_indices[i]]
            standard_signal = y_block[:, standard_indices[i]]

            # í—¬í¼ í•¨ìˆ˜ë¥¼ ì§ì ‘ í˜¸ì¶œí•˜ëŠ” ëŒ€ì‹  Ravgë¥¼ ì¤‘ê°„ì— ì¶”ì¶œí•©ë‹ˆë‹¤.
            eps = 1e-12
            top, bot = sensor_signal, standard_signal
            if self.params.r_abs:
                top, bot = np.abs(top), np.abs(bot)
            top, bot = np.maximum(top, eps), np.maximum(bot, eps)
            
            ratio = np.maximum(top / bot, eps)
            log_base = self.params.k if self.params.k > 1 else 10.0
            log_ratio = np.log(ratio) / np.log(log_base)
            
            scale = self.params.alpha * self.params.beta * self.params.gamma
            R = scale * log_ratio + self.params.b
            Ravg = moving_average(R, max(1, int(self.params.movavg_r)))
            
            # âœ… ê³„ì‚°ëœ Ravgë¥¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
            ravg_series.append(Ravg.tolist())

            # ë‚˜ë¨¸ì§€ y1, y2, y3, yt ê³„ì‚°
            safe_ravg = np.clip(Ravg, -1e9, 1e9)
            n = np.polyval(np.array(self.params.y1_num, dtype=float), safe_ravg)
            d = np.polyval(np.array(self.params.y1_den, dtype=float), safe_ravg)
            y1 = n / np.where(np.abs(d) < eps, eps, d)
            safe_y1 = np.clip(y1, -1e9, 1e9)
            y2 = np.polyval(np.array(self.params.y2_coeffs, dtype=float), safe_y1)
            safe_y2 = np.clip(y2, -1e9, 1e9)
            y3 = np.polyval(np.array(self.params.y3_coeffs, dtype=float), safe_y2)
            yt = self.params.E * y3 + self.params.F
            yt_series.append(sanitize_array(yt).astype(np.float32, copy=False).tolist())

        # ytì™€ Ravg ë°ì´í„°ë¥¼ ëª¨ë‘ í¬í•¨í•˜ì—¬ ë°˜í™˜
>>>>>>> Stashed changes
        return {
            "yt": {
                "kind": "yt_4_pairs",
                "names": ["yt0", "yt1", "yt2", "yt3"],
                "series": yt_series
            },
            "ravg": {
                "kind": "ravg_4_pairs",
                "names": ["Ravg0", "Ravg1", "Ravg2", "Ravg3"],
                "series": ravg_series
            }
        }

        # ---------- main loop ----------
    def _run(self):
        last_loop_end_time = time.time()
        # loop_count = 0  # ë¡œê·¸ ì¶œë ¥ì„ ì œì–´í•˜ê¸° ìœ„í•œ ì¹´ìš´í„°

        while not self._stop.is_set():
            t_start = time.time()
            try:
                # 1. C í”„ë¡œê·¸ë¨/í•˜ë“œì›¨ì–´ë¡œë¶€í„° ì›ë³¸ ë°ì´í„° ë¸”ë¡ì„ ì½ì–´ì˜µë‹ˆë‹¤.
                mat = self.src.read_block(self.block)
            except EOFError:
                print("[INFO] CProc source has ended. Shutting down pipeline thread.")
                break
            
            t_end = time.time()
            elapsed_ms = (t_end - t_start) * 1000
            # ë¸”ë¡ ì‹¤ì œë¡œ ì½ì–´ì˜¤ëŠ” í„°ë¯¸ë„ ë¡œê·¸
            #print(f"[DEBUG] Block read elapsed = {elapsed_ms:.3f} ms")

            # ##### DEBUG LOGGING START #####
            # C í”„ë¡œê·¸ë¨ì—ì„œ ë°›ì€ ë°ì´í„°ê°€ 0ì„ í¬í•¨í•˜ëŠ”ì§€ ì—¬ê¸°ì„œ ë°”ë¡œ í™•ì¸í•©ë‹ˆë‹¤.
            # ë„ˆë¬´ ìì£¼ ì¶œë ¥ë˜ë©´ í„°ë¯¸ë„ì´ ë©ˆì¶œ ìˆ˜ ìˆìœ¼ë¯€ë¡œ 10ë²ˆì— í•œ ë²ˆë§Œ ì¶œë ¥í•©ë‹ˆë‹¤.
            # if loop_count % 10 == 0:
            #     print("-" * 60)
            #     print(f"[PIPELINE-DEBUG] Raw Block Read (Source -> Python)")
            #     print(f"  - Shape: {mat.shape}")
            #     # ch0 (ìŠ¤íƒ ë‹¤ë“œ)ì™€ ch1 (ì„¼ì„œ)ì˜ ìµœì†Œ/ìµœëŒ€ê°’ì„ ì¶œë ¥í•©ë‹ˆë‹¤.
            #     # ë§Œì•½ min ê°’ì´ ê³„ì† 0.0000ìœ¼ë¡œ ë‚˜ì˜¨ë‹¤ë©´, C í”„ë¡œê·¸ë¨ë‹¨ì—ì„œë¶€í„° 0ì´ ì„ì—¬ ë“¤ì–´ì˜¨ ê²ƒì…ë‹ˆë‹¤.
            #     print(f"  - ch0 min/max: {mat[:,0].min():.4f} / {mat[:,0].max():.4f}")
            #     print(f"  - ch1 min/max: {mat[:,1].min():.4f} / {mat[:,1].max():.4f}")
            #     print("-" * 60)
            # loop_count += 1
            # ##### DEBUG LOGGING END #####

<<<<<<< Updated upstream
            t_read_done = time.time()

=======
            # [2] ë°ì´í„° í˜•íƒœ ë³´ì • (1D â†’ 2D, writeable ë³´ì¥)
>>>>>>> Stashed changes
            if mat.ndim == 1:
                mat = mat[:, None]
            if not mat.flags.writeable:
                mat = np.array(mat, dtype=np.float32, copy=True)

            # ##### [ì½”ë“œ ì¶”ê°€/ìˆ˜ì •] ì±„ë„ ìˆ˜ê°€ ë³€ê²½ë˜ë©´ í•„í„° ìƒíƒœë¥¼ ë¦¬ì…‹ #####
            n_ch = mat.shape[1]
            if n_ch != self._n_ch_last:
                # ì±„ë„ ìˆ˜ê°€ ë³€ê²½ë˜ë©´ LPF ìƒíƒœë¥¼ ì˜¬ë°”ë¥¸ shapeìœ¼ë¡œ ë‹¤ì‹œ ìƒì„±
                zi_one_ch = sosfilt_zi(self._sos)
                self._lpf_state = np.stack([zi_one_ch] * n_ch, axis=-1)
                self._n_ch_last = n_ch

            # Per-channel moving average (optional)
            if self.params.movavg_ch and self.params.movavg_ch > 1:
                for c in range(mat.shape[1]):
                    mat[:, c] = moving_average(mat[:, c], self.params.movavg_ch)

            # LPF
            zf_list = []
            for c in range(n_ch):
                zi_c = self._lpf_state[:, :, c]
                mat[:, c], zf_c = apply_lpf(mat[:, c], self._sos, zi=zi_c)
                zf_list.append(zf_c)
            if zf_list:
                self._lpf_state = np.stack(zf_list, axis=-1)
                
            ####### [ìˆ˜ì •ëœ ë¶€ë¶„ END] #####    

            # Decimation
            decim = max(1, int(self.fs / max(1.0, self.params.target_rate_hz)))
            y = mat[::decim, :].astype(np.float32, copy=False)

<<<<<<< Updated upstream
            # Sanitize
            y = sanitize_array(y)

            # ë¡¤ë§ ìœˆë„ìš° ë²„í¼ ì¤€ë¹„ (í•­ìƒ 8ì±„ë„)
            if self._roll_y is None:
                self._roll_y = np.zeros((self._roll_len, 8), dtype=np.float32)

            n_ch_actual = y.shape[1]
            if n_ch_actual < 8:
                y_padded = np.zeros((y.shape[0], 8), dtype=np.float32)
                y_padded[:, :n_ch_actual] = y
                y = y_padded
            elif n_ch_actual > 8:
                y = y[:, :8]

            k = min(y.shape[0], self._roll_len)
            self._roll_y = np.roll(self._roll_y, -k, axis=0)
            self._roll_y[-k:, :] = y[-k:, :]

            # ==========================================================
            # ===> ë³€ê²½ëœ íŒŒìƒ ì‹ í˜¸ ê³„ì‚° í•¨ìˆ˜ í˜¸ì¶œ
            # ==========================================================
            derived_signals = self._compute_derived_signals(y)
            # ==========================================================
=======
            # ì´ì „ ë£¨í”„ì˜ ì”ì—¬ ìƒ˜í”Œ ì´ì–´ë¶™ì´ê¸°
            if self._avg_tail.size > 0:
                mat = np.vstack([self._avg_tail, mat])

            if decim > 1:
                n_blocks = mat.shape[0] // decim
                if n_blocks > 0:
                    # ì •ìˆ˜ë°° ë¸”ë¡ë§Œ í‰ê· 
                    proc_chunk = mat[:n_blocks * decim]
                    y = proc_chunk.reshape(n_blocks, decim, -1).mean(axis=1).astype(np.float32, copy=False)
                    # ë‚¨ì€ ê¼¬ë¦¬ëŠ” ë‹¤ìŒ ë£¨í”„ë¡œ ì´ì›”
                    self._avg_tail = mat[n_blocks * decim:]
                else:
                    # ë°ì´í„° ë¶€ì¡± â†’ ì „ë¶€ ê¼¬ë¦¬ë¡œ ì´ì›”
                    self._avg_tail = mat
                    y = np.empty((0, mat.shape[1]), dtype=np.float32)

                # âœ… ë°©ì–´ ë¡œì§: ê¼¬ë¦¬ í¬ê¸° ì œí•œ (decim * 10 ë°° ì´ìƒ ê¸ˆì§€)
                MAX_TAIL = decim * 10
                if self._avg_tail.shape[0] > MAX_TAIL:
                    # ì˜¤ë˜ëœ ë°ì´í„°ëŠ” ë²„ë¦¬ê³  ìµœê·¼ ê²ƒë§Œ ìœ ì§€
                    self._avg_tail = self._avg_tail[-MAX_TAIL:]
                    print(f"[WARN] avg_tail truncated to {MAX_TAIL} samples (overflow prevention)")

            else:
                # decim == 1 â†’ ì›ë³¸ ìœ ì§€
                y = mat.astype(np.float32, copy=False)
                self._avg_tail = np.empty((0, mat.shape[1]), dtype=np.float32)

            # [7] NaN/Inf ì•ˆì „í™” ì²˜ë¦¬
            y = sanitize_array(y)


            # [9] íŒŒìƒ ì‹ í˜¸ ê³„ì‚° (yt0~yt3)
            computed_signals = self._compute_derived_signals(y)
>>>>>>> Stashed changes


            # â€¼ï¸ ---- ì„±ëŠ¥ ì¸¡ì • ë¡œì§ ì‹œì‘ ---- â€¼ï¸
            loop_end_time = time.time()
            loop_duration = loop_end_time - last_loop_end_time
            last_loop_end_time = loop_end_time

<<<<<<< Updated upstream
            stats = {
                "read_ms": (t_read_done - t_start) * 1000,
                "proc_ms": (time.time() - t_read_done) * 1000,
                "update_hz": 1.0 / loop_duration if loop_duration > 0 else 0,
                "proc_kSps": (self.block / loop_duration) / 1000.0 if loop_duration > 0 else 0,
            }
            
            ###### ë¡œê·¸ íŒŒì¼ì— ë°ì´í„° ì“°ê¸° (ì¡°ê±´ ì™„í™” ë° ì•ˆì •ì„± ê°•í™”) #####
            current_time = time.time()
            
            # --- ì‹¤ì‹œê°„ ì‹ í˜¸/íŒŒìƒ ê°’ ë¡œê¹… (stream_log.csv) ---
            # yì— ë°ì´í„°ê°€ í•œ ì¤„ì´ë¼ë„ ìˆìœ¼ë©´ ë¡œê·¸ ê¸°ë¡ ì‹œë„
=======
            # [10] ì²˜ë¦¬ í†µê³„(stats) ê³„ì‚°
            fs_hz = float(self.fs)
            blk_n = int(self.block)
            n_ch = y.shape[1] # â€¼ï¸ í˜„ì¬ ì²˜ë¦¬ì¤‘ì¸ ì±„ë„ ìˆ˜
            
            # ì´ë¡ ì ì¸ ë¸”ë¡ë‹¹ ì‹œê°„ (ms)
            theoretical_block_time_ms = (blk_n / fs_hz * 1000.0) if fs_hz > 0 else 0.0
            
            # ì‹¤ì œ ì¸¡ì •ê°’
            actual_block_time_ms = loop_duration * 1000.0
            actual_blocks_per_sec = 1.0 / loop_duration if loop_duration > 0 else 0.0
            # â€¼ï¸ ì´ ì²˜ë¦¬ëŸ‰ì„ ì±„ë„ ìˆ˜(n_ch)ë¡œ ë‚˜ëˆ„ì–´ ì±„ë„ë‹¹ ì²˜ë¦¬ëŸ‰ì„ ê³„ì‚°
            actual_proc_kSps = (blk_n / loop_duration / n_ch / 1000.0) if loop_duration > 0 and n_ch > 0 else 0.0

            stats = {
                "sampling_frequency": fs_hz,
                "block_samples": blk_n,
                "theoretical_block_time_ms": theoretical_block_time_ms,
                
                # â€¼ï¸ ì‹¤ì œ ì¸¡ì •ëœ ì„±ëŠ¥ ì§€í‘œ ì¶”ê°€
                "actual_block_time_ms": actual_block_time_ms,
                "actual_blocks_per_sec": actual_blocks_per_sec,
                "actual_proc_kSps": actual_proc_kSps,
                "n_ch": n_ch,
            }
            # â€¼ï¸ ---- ì„±ëŠ¥ ì¸¡ì • ë¡œì§ ë ---- â€¼ï¸

            # [11] ì£¼ê¸°ì  CSV ë¡œê¹… (stream_log.csv, perf_log.csv)
            current_time = time.time()

             # --- stream_log.csv (3ì´ˆ ì£¼ê¸°) ---
>>>>>>> Stashed changes
            if y.shape[0] > 0 and current_time - self._last_stream_log_time >= 3:
                self._last_stream_log_time = current_time # íƒ€ì´ë¨¸ ê°±ì‹ 
                
                ts_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f')[:-3]
                
<<<<<<< Updated upstream
                last_ch_values = y[-1, :8].tolist()
                
                if derived_signals and derived_signals.get("series") and all(s for s in derived_signals["series"]):
                    last_yt_values = [s[-1] for s in derived_signals["series"]]
                else:
                    last_yt_values = [0.0, 0.0, 0.0, 0.0]

                current_params = [
                    self.params.lpf_cutoff_hz,
                    self.params.movavg_r,
                    self.params.target_rate_hz
                ]
                
                log_row = [ts_str] + last_ch_values + last_yt_values + current_params
=======
                # 1. 8ê°œ ì±„ë„ì˜ ë§ˆì§€ë§‰ ê°’ ì¶”ì¶œ
                last_ch_values = y[-1, :8].tolist()

                # â€¼ï¸ 2. 4ê°œ Ravg ì‹ í˜¸ì˜ ë§ˆì§€ë§‰ ê°’ ì¶”ì¶œ
                ravg_data = computed_signals.get("ravg")
                last_ravg_values = [s[-1] for s in ravg_data["series"]] \
                                 if ravg_data and ravg_data.get("series") and all(s for s in ravg_data["series"]) \
                                 else [0.0, 0.0, 0.0, 0.0]

                # 3. 4ê°œ yt ì‹ í˜¸ì˜ ë§ˆì§€ë§‰ ê°’ ì¶”ì¶œ
                yt_data = computed_signals.get("yt")
                last_yt_values = [s[-1] for s in yt_data["series"]] \
                                if yt_data and yt_data.get("series") and all(s for s in yt_data["series"]) \
                                else [0.0, 0.0, 0.0, 0.0]
                
                # â€¼ï¸ 4. ìµœì¢… ë¡œê·¸ í–‰ì„ (ì‹œê°„ + ch + Ravg + yt) ìˆœì„œë¡œ ì¡°í•©
                log_row = [ts_str] + last_ch_values + last_ravg_values + last_yt_values
>>>>>>> Stashed changes
                
                with open(self._stream_log_path, 'a', newline='', encoding='utf-8') as f:
                    writer = csv.writer(f)
                    writer.writerow(log_row)

            # --- ì„±ëŠ¥ ë°ì´í„° ë¡œê¹… (perf_log.csv) - 10ì´ˆì— í•œë²ˆ ---
            if current_time - self._last_perf_log_time >= 10:
                self._last_perf_log_time = current_time
                ts_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                
                log_row = [
                    ts_str,
<<<<<<< Updated upstream
                    f"{stats['read_ms']:.2f}",
                    f"{stats['proc_ms']:.2f}",
                    f"{stats['update_hz']:.2f}",
                    f"{stats['proc_kSps']:.2f}"
=======
                    stats.get("sampling_frequency", 0)  / 1000.0,  # kS/së¡œ ë³€í™˜,
                    stats.get("block_samples", 0),
                    # â€¼ï¸ UIì™€ ë™ì¼í•œ 'ì‹¤ì œ ì¸¡ì •ê°’'ì„ ê¸°ë¡í•˜ë„ë¡ ë³€ê²½
                    stats.get("actual_block_time_ms", 0.0),
                    stats.get("actual_blocks_per_sec", 0.0),
                    stats.get("actual_proc_kSps", 0.0),
>>>>>>> Stashed changes
                ]
                
                with open(self._perf_log_path, 'a', newline='', encoding='utf-8') as f:
                    writer = csv.writer(f)
                    writer.writerow(log_row)
            ###### [ë¡œê·¸ ë] #####

            payload = {
                "type": "frame",
                "ts": time.time(),
                "n_ch": int(y.shape[1]),
                "y_block": y.tolist(), # âœ… ì²˜ë¦¬ëœ ìƒˆ ë°ì´í„° ë¸”ë¡ ì¶”ê°€
                "block": {
                    "n": int(y.shape[0]),
                    "sample_stride": decim,
                },
<<<<<<< Updated upstream
                "derived": derived_signals,  # <--- ì—¬ê¸°ì— ìƒˆë¡œìš´ ê²°ê³¼ ì‚½ì…
                "stats": stats,
                "params": self.params.model_dump(),
                # "multi" í‚¤ëŠ” ë” ì´ìƒ í•„ìš” ì—†ìœ¼ë¯€ë¡œ ì œê±°
            }
            self._broadcast(payload)
=======
                "stats": stats,
                "params": self.params.model_dump(),
                "derived": computed_signals.get("yt"),
                "ravg_signals": computed_signals.get("ravg"),
            }
            self._broadcast(payload)

>>>>>>> Stashed changes
